{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "##from pandas.plotting import parallel_coordinates\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "plt.style.use(\"seaborn-dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cantidad de lugares distintos de la base de datos </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['Location'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Hacemos una copia del la base de datos para cambiar los valores de 'yes' y 'no' por valores booleanos en la copia del DF </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RainToday'] = (data['RainToday'] == 'Yes')*1\n",
    "data['RainTomorrow'] = (data['RainTomorrow'] == 'Yes')*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cambiamos las abreviaciones de las direcciones del viento en las respectivas columnas </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ab_WD = ['N','NNE','NE','ENE','E','ESE','SE','SSE','S', 'SSW','SW','WSW','W','WNW','NW','NNW']\n",
    "WD = [0,22.5,45,67.5,90,112.5,135,157.5,180,202.5,225,247.5,270,292.5,315,337.5]\n",
    "Wind_Dir = pd.DataFrame()\n",
    "Wind_Dir['Ab_WD']=Ab_WD\n",
    "Wind_Dir['WD']=WD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in Wind_Dir.index:\n",
    " #   datc.loc[datc['WindGustDir']== Wind_Dir.iloc[i][0],'WindGustDir']= Wind_Dir.iloc[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in Wind_Dir.index:\n",
    " #   datc.loc[datc['WindDir9am']== Wind_Dir.iloc[i][0],'WindDir9am']= Wind_Dir.iloc[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in Wind_Dir.index:\n",
    " #   datc.loc[datc['WindDir3pm']== Wind_Dir.iloc[i][0],'WindDir3pm']= Wind_Dir.iloc[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Col_WindDir=['WindGustDir','WindDir9am','WindDir3pm']\n",
    "for j in Col_WindDir:\n",
    "    for i in Wind_Dir.index:\n",
    "        data.loc[data[j] == Wind_Dir.iloc[i][0], j]= Wind_Dir.iloc[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Ahora veamos la cantidad de valores nulos que hay en la base de datos</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cantidad de calores nulos </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Calculemos los coeficientes de correlación de la base de datos para darnos una idea de que columnas pueden ser de utlidad y cuales no. </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_data = data.corr()\n",
    "cor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Visualicemos esto con un gráfico </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(cor_data,annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cantidad de calores nulos en porcentaje </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.isnull().sum()*100)/len(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dado que queremos un modelo que prediga si lloverá o no en una o varias de las ciudades de la base de datos, lo que haremos será optar por predecir con un modelo de árbol de desiciones (clasificador) </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Puesto que queremos predecir especificamente en cada ciudad, como primer acercamiento separaremos los datos de cada ciudad en la base de datos y la limpiaremos para proceder a crear el modelo. </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto creamos un diccionario que contenga las bases de datos de cada lugar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loc = data['Location'].unique()\n",
    "df_dict_Loc = {elem : pd.DataFrame() for elem in Loc}\n",
    "for key in df_dict_Loc.keys():\n",
    "    df_dict_Loc[key] = data[:][data.Location == key]\n",
    "df_dict_Loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_Loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedemos a limpiar cada base de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero sera ver cuantos (porcentaje) valores nulos hay en cada base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_val_perc = {elem : pd.Series(dtype='float64') for elem in Loc}\n",
    "for key in df_dict_Loc.keys():\n",
    "    null_val_perc[key] = (df_dict_Loc[key].isnull().sum()*100)/len(df_dict_Loc[key].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_val_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las columnas con mas valores nulos y borremos las columnas que tengan todos sus valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in null_val_perc.keys():\n",
    "    for col in df_dict_Loc[key].columns:\n",
    "        if null_val_perc[key][col] == 100.0:\n",
    "            df_dict_Loc[key]=df_dict_Loc[key].drop([col],axis=1)\n",
    "            null_val_perc[key]=null_val_perc[key].drop([col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_Loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_val_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que todavia hay columnas con valores nulos, en esta ocasión optaremos por rellenar los valores con la media o moda dependiendo del tipo de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas que se rellenan con la moda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Col_Mode =['WindGustDir','WindDir9am','WindDir3pm','Cloud9am','Cloud3pm']\n",
    "for key in df_dict_Loc.keys():\n",
    "    for col in Col_Mode:\n",
    "        if col in df_dict_Loc[key].columns:\n",
    "            df_dict_Loc[key][col]=df_dict_Loc[key][col].fillna(df_dict_Loc[key][col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas que se rellenan con la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_dict_Loc.keys():\n",
    "    df_dict_Loc[key].fillna(df_dict_Loc[key].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora no hay base de datos con valores nulos. Corroboremos esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_val_perc = {elem : pd.Series(dtype='float64') for elem in Loc}\n",
    "for key in df_dict_Loc.keys():\n",
    "    null_val_perc[key] = (df_dict_Loc[key].isnull().sum()*100)/len(df_dict_Loc[key].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_val_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ahora veamos los coeficientes de correlación y decidamos con cuales características qeudarnos \n",
    "para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_corr = {elem : pd.DataFrame() for elem in Loc}\n",
    "for key in df_dict_Loc.keys():\n",
    "    coef_corr[key]= df_dict_Loc[key].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in df_dict_Loc.keys():\n",
    "    plt.figure(figsize=(20,12))\n",
    "    sns.heatmap(coef_corr[key],annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo elegiremos las columnas con coeficientes cuyos valores absolutos son\n",
    "mayores o iguales a .1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coeficientes positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_corr_p = {elem : pd.DataFrame() for elem in Loc}\n",
    "for key in df_dict_Loc.keys():\n",
    "    coef_corr_p[key]= coef_corr[key][coef_corr[key]['RainTomorrow']>= .1]\n",
    "    coef_corr_p[key]=coef_corr_p[key].drop(['RainTomorrow'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_corr_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coeficientes negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_corr_n = {elem : pd.DataFrame() for elem in df_dict_Loc.keys()}\n",
    "for key in df_dict_Loc.keys():\n",
    "    coef_corr_n[key]= coef_corr[key][coef_corr[key]['RainTomorrow']<= -.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_corr_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tomemos esas características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = {elem : list() for elem in Loc}\n",
    "for key in df_dict_Loc.keys():\n",
    "    total_len[key].append(len(coef_corr_p[key].index) +len(coef_corr_n[key].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len['Albury'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {elem : list() for elem in Loc}\n",
    "for key in df_dict_Loc.keys():\n",
    "    for i in range(0,total_len[key][0]):\n",
    "        if i<=(len(coef_corr_p[key])-1):\n",
    "            features[key].append(coef_corr_p[key].index[i])\n",
    "        elif i >= len(coef_corr_p[key]):\n",
    "            features[key].append(coef_corr_n[key].index[i-(len(coef_corr_p[key])+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pasemos a crear los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {elem : pd.DataFrame() for elem in Loc}\n",
    "for key in df_dict_Loc.keys():\n",
    "    X[key]= df_dict_Loc[key][features[key]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = {elem : pd.DataFrame() for elem in Loc}\n",
    "for key in df_dict_Loc.keys():\n",
    "    y[key]= df_dict_Loc[key][['RainTomorrow']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos todo para hacer el modelo, podemos elegir cualquier \"llave \" del\n",
    "diccionario y ver que tan bueno es el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Canberra'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[key], y[key], test_size=0.33, random_state=324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_met=pd.DataFrame(columns=['node','accuracy'],index=range(22))\n",
    "for i in range(3,25):\n",
    "    Rain_Tomorrow = DecisionTreeClassifier(max_leaf_nodes=i, random_state=0)\n",
    "    Rain_Tomorrow.fit(X_train, y_train)\n",
    "    predictions = Rain_Tomorrow.predict(X_test)\n",
    "    j=i-3\n",
    "    val_met.iloc[j][0] = i \n",
    "    val_met.iloc[j][1]=(accuracy_score(y_true = y_test, y_pred = predictions))\n",
    "    print(i,' ',accuracy_score(y_true = y_test, y_pred = predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
